{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.12)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ({\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.78\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get universities with their links\n",
    "def getUniversities():\n",
    "  with open(\"./data/universities.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Name\", \"Link\"])\n",
    "    providerURL = \"https://www.classcentral.com/universities\"\n",
    "    providerPage = requests.get(providerURL, headers=HEADERS)\n",
    "\n",
    "    soup = bs(providerPage.content, \"lxml\")\n",
    "    providerList = soup.find_all(attrs={ \"class\" : \"row vert-align-middle color-charcoal hover-bg-blue-xlight padding-vert-small padding-horz-medium nowrap\" })\n",
    "    for i in providerList:\n",
    "      try:\n",
    "        string = str(i.text.strip())\n",
    "        string = string[:string.index(\"\\n\")]\n",
    "        linkProviders = [str(string),str(i.text.strip()), str(i.get(\"href\"))]\n",
    "        writer.writerow(linkProviders)\n",
    "        print(linkProviders)\n",
    "      except:\n",
    "        print(\"Error\")\n",
    "\n",
    "# getUniversities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get institution with their links\n",
    "def getInstitutions():\n",
    "  with open(\"./data/institution.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Name\", \"Link\"])\n",
    "    providerURL = \"https://www.classcentral.com/institutions\"\n",
    "    providerPage = requests.get(providerURL, headers=HEADERS)\n",
    "\n",
    "    soup = bs(providerPage.content, \"lxml\")\n",
    "    providerList = soup.find_all(attrs={ \"class\" : \"row vert-align-middle color-charcoal hover-bg-blue-xlight padding-vert-small padding-horz-medium nowrap\" })\n",
    "    for i in providerList:\n",
    "      try:\n",
    "        linkProviders = [str(i.text.strip()), str(i.get(\"href\"))]\n",
    "        writer.writerow(linkProviders)\n",
    "        print(linkProviders)\n",
    "      except:\n",
    "        print(\"Error\")\n",
    "      \n",
    "# getInstitutions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get provider with their links\n",
    "\n",
    "def getProvider():\n",
    "  with open(\"./data/providers.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Name\", \"Link\"])\n",
    "    providerURL = \"https://www.classcentral.com/providers\"\n",
    "    providerPage = requests.get(providerURL, headers=HEADERS)\n",
    "\n",
    "    soup = bs(providerPage.content, \"lxml\")\n",
    "    providerList = soup.find_all(attrs={ \"class\" : \"row nowrap vert-align-middle text-1 hover-bg-gray-xlight hover-no-underline weight-semi color-charcoal padding-vert-medium padding-horz-small\" })\n",
    "    for i in providerList:\n",
    "      try:\n",
    "        linkProviders = [str(i.text.strip()), str(i.get(\"href\"))]\n",
    "        writer.writerow(linkProviders)\n",
    "        print(linkProviders)\n",
    "      except:\n",
    "        print(\"Error\")\n",
    "      \n",
    "# getProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scraper(numberOfUniversities):\n",
    "  with open('./data/universities.csv') as file_obj:\n",
    "    \n",
    "    heading = next(file_obj)\n",
    "    universities = csv.reader(file_obj)\n",
    "    universities = list(universities)\n",
    "    \n",
    "    with open('countries2.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "      iteration = 0\n",
    "      writer = csv.writer(f)\n",
    "      header = [\"Course Name\", \"Course Description\",\"Course University\",\"Course University Tag\" ,\"Course Link\", \"Course Provider\", \"Course Duration\", \"Course Pricing\"]\n",
    "      writer.writerow(header)\n",
    "      while iteration < numberOfUniversities:\n",
    "        row = universities[iteration]\n",
    "        print(\"University Name: \"+str(row[0]))\n",
    "        print(\"University Link: \"+str(row[2]))\n",
    "        numberOfCourses =  str(row[1]).split(\" \")[-2]\n",
    "        Url = \"https://www.classcentral.com\"+str(row[2])\n",
    "        webpage = requests.get(str(Url), headers=HEADERS)\n",
    "        time.sleep(2)\n",
    "        soup = bs(webpage.content, \"lxml\")\n",
    "        # numberOfCourses = soup.findAll(attrs={'class':'hidden small-up-inline-block'})\n",
    "        # numberOfCourses = str(numberOfCourses[0].text.strip())\n",
    "        print(\"Number of courses available: \"+numberOfCourses+\" courses\")\n",
    "        numberOfCourses = numberOfCourses.split(\" \")[-1]\n",
    "        numberOfPages = int(numberOfCourses)//15\n",
    "        print(\"Number of pages: \"+str(numberOfPages) + \" pages\")\n",
    "        i = 1\n",
    "        while i <= numberOfPages:\n",
    "          start = time.time()\n",
    "          webpage = requests.get(str(Url+\"?page=\"+str(i)), headers=HEADERS)\n",
    "          time.sleep(1)\n",
    "          soup = bs(webpage.content, \"lxml\") \n",
    "          courseName = soup.findAll(attrs={'class':'text-1 weight-semi line-tight margin-bottom-xxsmall'})\n",
    "          courseDescription = soup.findAll(attrs={'class':'color-charcoal block hover-no-underline break-word'})\n",
    "          # courseLink = soup.findAll(attrs={'class':'block hover-no-underline'})\n",
    "          courseProvider = soup.findAll(attrs={'class':'hover-underline color-charcoal text-3 margin-left-small line-tight', \"aria-label\":\"Provider\"})\n",
    "          courseUniversity = str(row[0])\n",
    "          courseUniversityTag = str(row[2]).split(\"/\")[-1]\n",
    "          courseDuration = soup.findAll(attrs={'class':'text-3 margin-left-small line-tight', \"aria-label\":\"Workload and duration\"})\n",
    "          coursePricing = soup.findAll(attrs={'class':'text-3 margin-left-small line-tight', \"aria-label\":\"Pricing\"})\n",
    "          if len(courseName) >= 10:\n",
    "            for m in range(len(courseName)): \n",
    "              try:\n",
    "                result = [courseName[m].text.strip(), courseDescription[m].text.strip(),courseUniversity,courseUniversityTag,str(courseDescription[m].get(\"href\")), courseProvider[m].text.strip(), courseDuration[m].text.strip(), coursePricing[m].text.strip()]\n",
    "                writer.writerow(result)\n",
    "              except:\n",
    "                print(\"List index out of range\")\n",
    "                pass\n",
    "            end = time.time()\n",
    "            print(\"Found \" + str(len(courseName)) + \" courses in page \"+ str(i)+ \"   \" + str(numberOfPages-i) + \" pages left\" + \"   \" + str(int(end-start)) + \" seconds\" + \"    \" + str(((numberOfPages-i)/numberOfPages)*100) + \" %\")\n",
    "            i += 1\n",
    "          iteration += 1\n",
    "            \n",
    "\n",
    "scraper(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import csv\n",
    "\n",
    "\n",
    "clustering = pymongo.MongoClient(\"mongodb+srv://adithyask:adithyask@courses.9v6zz7i.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db = clustering[\"courses\"]\n",
    "collection = db[\"universities\"]\n",
    "# Open the CSV file\n",
    "\n",
    "courses = []\n",
    "\n",
    "with open('./countries2.csv', encoding='utf-8') as csv_file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in csv_reader:\n",
    "        document = {\"name\": row[0], \"description\": row[1],\"university\":row[2],\"universityTag\":row[3] ,\"link\": row[4], \"provider\": row[5], \"duration\": row[6], \"pricing\": row[7]}\n",
    "        courses.append(document)\n",
    "    \n",
    "    print(courses)\n",
    "        # collection.insert_one(document)\n",
    "\n",
    "# document_101 = [{\"name\": \"hello\" },{ \"name\": \"world\" }]\n",
    "# collection.insert_many(document_101)\n",
    "\n",
    "collection.insert_many(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "def delete_database():\n",
    "  clustering = pymongo.MongoClient(\"mongodb+srv://adithyask:adithyask@courses.9v6zz7i.mongodb.net/?retryWrites=true&w=majority\")\n",
    "  db = clustering[\"courses\"]\n",
    "  collection = db[\"universities\"]\n",
    "  # Delete the collection\n",
    "  collection.delete_many({})\n",
    "  \n",
    "# delete_database()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
